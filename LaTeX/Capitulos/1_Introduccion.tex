\chapter{Introducción}

En este capítulo se presenta una perspectiva general del contexto en el que se ha llevado a cabo el proyecto. Además de las dificultades enfrentados durante su desarrollo para alcanzar las contribuciones mencionadas, se detallan cada uno de los propósitos perseguidos en él.


\section{Definición y alcance del proyecto}

	El desarrollo de las Inteligencias Artificiales en nuestra sociedad ha sido un fenómeno de gran relevancia, además de popular, en los últimos años. Estas tecnologías han llegado para quedarse y están mejorando nuestra calidad de vida. Desde la automatización de tareas hasta la asistencia virtual\cite{lugano2017virtual}, estas IAs desempeñan un papel cada vez más importante en nuestro día a día.
	Con el advenimiento del Internet de alta velocidad y la proliferación de datos, las empresas tecnológicas se enfrentan a la necesidad creciente de desarrollar servicios de alta calidad en un mercado muy competitivo. Actualmente, se invierte mucho dinero y tiempo en mejorar y diseñar algoritmos para implementar Inteligencias Artificiales para el acceso público\cite{thomas2021global}.
	
	El entrenamiento y ejecución de estos algoritmos para modelar inteligencias artificiales consumen mucha energía, además de provocar una cantidad excesiva de emisiones de CO\(_2\). La empresa tecnológica \textit{Hugging Face}, desarrolladora de \textit{BLOOM}\cite{BloomAI}, la primera LLM (Grandes Modelos de Lenguaje) multilenguaje entrenada de forma transparente, tuvo la colaboración de muchos investigadores. Este proyecto, con 176 mil millones de parámetros, es capaz de generar texto en 46 idiomas y 13 lenguajes de programación, pero estimaron que el entrenamiento de esta inteligencia artificial emitió 25 toneladas de CO\(_2\). Cifra que se duplicó al contar el coste de producción del equipo informático usado\cite{kirkpatrick2023carbon}. Los investigadores se están enfocando en evaluar y reducir el impacto ambiental de las tecnologías de IA. Una prueba de ello es el desarrollo de \textit{CarbonTracker}\cite{jeppesen2021carbon} (CTI), un equipo de especialistas financieros que asumen el riesgo climático como realidad de los mercados financieros actuales. El objetivo de esta herramienta es predecir y reducir la huella de carbono de las etapas de entrenamiento de los modelos de IA\cite{mor2021artificial}.
	
	El uso de la programación distribuida, más específicamente, aplicaciones basadas en MPI, permite ejecutar varios procesos en paralelo, dividiendo la carga de trabajo, reduciendo así el tiempo de ejecución. Al contrario de los programas basados en el modelo de memoria compartida, en el cual se pueden dar problemas de sincronización, cada proceso generado tiene su propia memoria local, evadiendo estos problemas. Sin embargo, hay que diseñar implementaciones correctas y eficientes para no tener más complejidad espacial de la esperada. Las conexiones entre los procesos se pueden configurar para maximizar la eficiencia y reducir el tiempo de cómputo. Una de las más populares es el modelo \textit{Master-Worker}. El proceso \textit{Master} se encarga de distribuir el trabajo a los procesos \textit{Workers}, para, en paralelo, ejecutar la misma tarea pero con conjuntos mucho más reducidos de datos. Al finalizar la tarea, el \textit{Worker} envía su salida, y si el proceso \textit{Master} no ha terminado, espera para recibir más datos. MPI permite la comunicación eficiente entre procesos, mejorando la escalabilidad y reduciendo el tiempo de procesamiento. Esta metodología, además de mejorar el rendimiento, también simplifica la gestión de recursos, mejorando la utilización del hardware disponible en el sistema. 
	
	Los algoritmos de IA suelen manejar un vasto número de datos para entrenar y evaluar los modelos deseados. Por eso es fundamental diseñar estrategias para distribuir los datos y dividir las cargas de trabajo de manera equitativa, controlando el flujo de datos para evitar cuellos de botella, y equilibrar los recursos disponibles. Esto incluye, además de la optimización del tiempo de ejecución, una gestión efectiva de la memoria (complejidad espacial) y minimizar la latencia (tiempo de espera en transmitir los paquetes de información en una red) en la comunicación entre los procesos.
	En este proyecto se diseñarán e implementarán varias optimizaciones para diferentes algoritmos de IA con el objetivo de reducir el tiempo de ejecución.





\section{Motivación}
	Actualmente hay muchas implementaciones de algoritmos de IA. Scikit learn es una biblioteca de Python adecuada para probar cualquier técnica. Esta biblioteca, como la mayoría, ejecuta los algoritmos de manera secuencial, sin dividir la carga de trabajo.  Las implementaciones están estudiadas y perfeccionadas para realizar los cálculos en un único proceso, pero se puede reducir el tiempo de ejecución aplicando paralelismo. 
	
	Las arquitecturas distribuidas junto con las técnicas de cómputo de alto rendimiento (HPC, por sus siglas en inglés), son una de las soluciones más apropiadas para los usuarios finales: científicos y empresas. La búsqueda de un rendimiento óptimo, bajo una perspectiva técnica en sistemas altamente distribuidos, demandan enfoques adaptables y escalables para implementar aplicaciones científicas de alto rendimiento. Sincronizar los procesos, distribuir los datos para aumentar el paralelismo y reducir el overhead, son los desafíos recurrentes en los sistemas distribuidos. La comunicación tiene que ser controlada para el correcto funcionamiento, y, en algunas ocasiones, estas mejoras derivan en implementaciones más complejas.
	
	Generalmente, en estos casos, es desafiante controlar las acciones de cada proceso para obtener la especificación deseada. Cada algoritmo tiene su funcionamiento y su desempeño, al igual que implementación única.
	
	Las empresas tecnológicas buscan mejorar el rendimiento y reducir costes de sus sistemas. Para ello, es necesario un uso eficiente de los recursos computacionales. Además, existe un interés en reducir el consumo de energía y las emisiones de CO\(_2\), al entrenar o procesar modelos de IA, puesto que el impacto ambiental está en auge hoy en día.  Contando con una gran competitividad en el mercado tecnológico, cualquier mejora, aunque no sea excesivamente significativa, es un avance.

	\newpage


\section{Objetivo}

	El objetivo principal de este trabajo es \textbf{paralelizar algoritmos de IA, empleando técnicas de HPC para reducir el tiempo de ejecución}. Entre los algoritmos a optimizar se encuentran técnicas como el agrupamiento de individuos, predicción de resultados y la optimización de funciones de evaluación. Todas estas implementaciones han sido desarrolladas en Python, el lenguaje de programación más popular en el ámbito de la inteligencia artificial\cite{sainin2021best}. Sin embargo, al ser un lenguaje interpretado (el código se traduce en la misma ejecución), aumenta la sobrecarga y hace que -generalmente- el programa sea más lento que la misma implementación en otros lenguajes. Por eso Python es el lenguaje de programación idóneo para aplicar técnicas de cómputo de alto rendimiento y reducir el tiempo de ejecución.
	
	Asimismo, se requerirá alcanzar los siguientes objetivos secundarios:
	
	\begin{enumerate}
		\item \textbf{Diseño de implementaciones escalables y flexibles.} Al diseñar e implementar mejoras de cada algoritmo, es posible utilizar distintos números de procesos en la ejecución. Esto permite un estudio profundo de las implementaciones realizadas. Al variar el número de procesos se puede comprobar cuál es el número idóneo para cualquier implementación. La flexibilidad en las mejoras permite variar los datos de entrada para que funcione correctamente con un tamaño de \textit{dataset} variable.
		\item \textbf{Correcto funcionamiento de los algoritmos.} Al realizar las mejoras, además de mejorar el rendimiento, es necesario tener una cohesión con el algoritmo original. Es decir, si queremos maximizar una función de evaluación, la implementación de la mejora tiene que proporcionar resultados parecidos o mejores. No resulta útil implementar una mejora que reduzca el tiempo de ejecución, pero que obtenga resultados peores.
		\item \textbf{Estudio empírico.} Se realizará una evaluación de las mejoras para calcular el aumento del rendimiento. Primero se mide el tiempo que tarda cada algoritmo sin mejoras y, posteriormente, se analizan las diferentes implementaciones desarrolladas variando el número de procesos ejecutados. Para finalizar, se prueban las mejores implementaciones de cada algoritmo en el sistema distribuido con 128 núcleos.
	\end{enumerate}





\section{Estructura del documento}
	El resto de este documento está organizado en los siguientes capítulos:
	
	
	\begin{itemize}
		\item Capítulo \hyperref[cap:c2_context]{2}: Contextualización. En este capítulo se proporciona información de cada algoritmo estudiado.
		\item Capítulo \hyperref[cap:c3_implementaciones]{3}: Diseño e implementaciones. Este capítulo comienza describiendo ejemplos básicos fuera del ámbito de la inteligencia artificial. Seguidamente, se muestran las implementaciones desarrolladas para las diferentes técnicas abordadas.
		\item Capítulo \hyperref[cap:c4_estudio]{4}: Estudio empírico, presenta el proceso experimental realizado, el cual consiste en analizar las mejoras propuestas, variando el número de procesos y el tamaño de los datos. 
		\item Capítulo \hyperref[cap:c5_conclu]{5}: Conclusiones y trabajo a futuro. El último capítulo finaliza el trabajo con una síntesis  de los resultados obtenidos, y presenta la proyección del trabajo a futuro.
	\end{itemize}
















%The document is divided into \texttt{chapters}, \texttt{sections}, and \texttt{subsections}.
%
%Some important references are \cite{einstein,latexcompanion,knuthwebsite}.
%
%To add paragraphs in the document, 
%one line break is not enough,
%
%two line breaks are needed.
%
%An itemized list:
%
%\begin{itemize}
%	\item An item.
%	\item Another item.
%	\item Final item.
%\end{itemize}
%
%An enumerated list:
%
%\begin{enumerate}
%	\item First item.
%	\item Second item.
%	\item Third item.
%\end{enumerate}
%
%A figure with an image is presented in \Cref{fig:figura}. Note that it floats away and latex places it where convenient.
%
%\begin{figure}[h!] % h de here con signo o sin b abajo t al principio
%	\centering
%	\includegraphics[width=0.4\textwidth]{Images/escudo_ucm.pdf}
%	\caption{Sample figure} % DESCRIPCION
%	\label{fig:figura}
%\end{figure}
%
%
%Tables work in the same way, as seen in \Cref{tab:tabla}
%
%\begin{table}
%	\centering
%	\begin{tabular}{c|c|c}
%		Row & English & Español \\\hline\hline
%		1 & One & Uno \\
%		2 & Two & Dos \\
%	\end{tabular}
%	\caption{Sample table}
%	\label{tab:tabla}
%\end{table}
%
%
%
%TODO QUITAR TABS \usepackage{parskip}
%
%\lstset{language=python, breaklines=true, basicstyle=\footnotesize}
%\begin{lstlisting}[frame=single]
%	# Prueba
%	print("Hola Mundo\n")
%	
%\end{lstlisting}
%
%-_-
%-\_-
%\%
%\#
%@
%º
















