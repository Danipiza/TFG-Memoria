\chapter*{Conclusions and future work}
\label{cap:c5_conclu_en}

	
	In this work, several improvements have been developed in different AI algorithms, through the standard MPI message passing library. The challenges encountered during its development turned out to be more complex than initially anticipated. The problems with configuring the MPI library in Windows, as well as adapting the management of Python libraries using Anaconda, were completely unforeseen problems. The general lack of knowledge of MPI is due to the absence of specific programming subjects distributed in the Computer Science degree, only offering theoretical foundations, without delving into practice. The execution of the tests in the highly distributed system of the Faculty of Informatics, together with the documentation of the work developed, took more time than estimated. However, it was an extremely rewarding and interesting stage.
	
	
	Once the proposed strategies were finalized, an experimentation phase was carried out, which consisted of analyzing the execution times, varying both the available parameters and the sets of populations for each type of algorithm. It is worth highlighting the high computational cost of the experiments. For example, in the hierarchical agglomerative algorithm with single link distance, a test on the highly distributed system required more than a day to complete, forcing the size of the population used to be reduced. It is important to note that some of the results obtained did not coincide with the expected trend. In particular, the segmentation strategy carried out in neural networks, where the performance achieved was worse than the sequential algorithm despite having -at least- three processes. Apart from having the results obtained in the same strategy but for the evolutionary algorithms, in which good results were obtained. After performing an analysis, we observed that the cause of these results is due to having two message flows in opposite directions. The importance of good results is equivalent to obtaining results that are not as effective as expected, since it is an advance to draw conclusions or other ideas to implement.
	
	
	One of the most important things I have learned throughout this work is that \textit{more is not always better}. Increasing the computational resources does not always have a proportional impact on the overall system performance. The \textit{overhead} of processes in implementations is a fundamental thing to take into account when executing programs, and in life itself.	
	
	
	As future work, it is proposed to investigate other algorithms of the developed techniques, in addition to investigating and improving other AI techniques, such as natural language processing.
	
	
	
	
	